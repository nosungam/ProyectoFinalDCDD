# üß† Proyecto Final: Modelo Predictivo de Burnout

Este repositorio contiene el c√≥digo y los recursos utilizados para el **Proyecto Final Integrador del Diplomado en Ciencia de Datos y An√°lisis Avanzado**.  
El objetivo es **predecir el riesgo de burnout en una poblaci√≥n de estudio (m√©dicos) en CABA**, trabajando con t√©cnicas avanzadas de Machine Learning y Deep Learning, siguiendo un flujo completo utilizando la metodolog√≠a CRISP-DM para el enfoque y la resoluci√≥n del problema planteado.

---

## üìÇ Contenido del Repositorio

| Archivo | Descripci√≥n |
|----------|--------------|
| **Exploracion de datos.ipynb** | Script Python para la *Exploraci√≥n de Datos*. Realiza la carga de la base, limpieza inicial (eliminaci√≥n de columnas irrelevantes, manejo de valores 999), c√°lculo de estad√≠sticas descriptivas (media, varianza, asimetr√≠a, curtosis), identificaci√≥n de duplicados y generaci√≥n de visualizaciones de distribuciones y correlaciones. |
| **DNN-final.ipynb** | Implementaci√≥n del modelo **Deep Neural Network (DNN)** para clasificaci√≥n (*MBI_Burnout*) y regresi√≥n (*MBI_RiesgoBurnout1*). Incluye preprocesamiento, escalado, aplicaci√≥n de SMOTE y entrenamiento con *K-Fold Cross Validation*. |
| **KNN Proyecto Final.ipynb** | Implementaci√≥n del modelo **K-Nearest Neighbors (KNN)**. Detalla la selecci√≥n de caracter√≠sticas basada en importancia (*Random Forest*), reducci√≥n de dimensionalidad y el uso de *RobustScaler* y *RandomOverSampler*. |
| **SVM Proyecto Final.ipynb** | Implementaci√≥n del modelo **Support Vector Machine (SVM)**. Se enfoca en la selecci√≥n de las 30 mejores caracter√≠sticas mediante *SelectKBest* y la optimizaci√≥n de hiperpar√°metros (*GridSearchCV*). |
| **xgboost-final.ipynb** | Implementaci√≥n del modelo **XGBoost** para clasificaci√≥n y regresi√≥n. Realiza la imputaci√≥n y conversi√≥n de tipos, transformaci√≥n logar√≠tmica para manejar la asimetr√≠a y an√°lisis de la importancia de caracter√≠sticas. |
| **Modelo arbol decision.csv** | Implementaci√≥n del modelo **√Årbol de decisi√≥n**. Muestra los nodos con las decisiones de clasificaci√≥n basadas en los factores m√°s relevantes. Se prioriza la interpretabilidad del modelo, permitiendo visualizar las divisiones y umbrales clave que determinan los niveles de riesgo. |
| **Regresion Logistica.csv** | Implementaci√≥n del modelo **Regresi√≥n Logist√≠ca**. Se analizan los coeficientes para identificar el peso de cada predictor sobre la probabilidad de presentar Burnout, aportando una base comparativa frente a modelos m√°s complejos. |
| **Proyecto_final.csv** | Dataset de entrada utilizado para todo el an√°lisis. |
| **Encuesta_Final_SinProcesar.csv** | Datos iniciales sin procesamiento. Contiene la explicaci√≥n de las variables. |



---

## ‚öôÔ∏è Requisitos

Para ejecutar los archivos de tipo notebook, se requiere un entorno configurado con las siguientes dependencias:

- **Python 3.11 o superior (recomendado)**
- **Librer√≠as de an√°lisis y visualizaci√≥n:** `pandas`, `numpy`, `matplotlib`, `seaborn`
- **Librer√≠as de Machine Learning:** `scikit-learn`
- **Librer√≠as de Modelos avanzados:** `xgboost`, `tensorflow`, `keras`
- **Librer√≠as de Desbalanceo:** `imblearn` (*para SMOTE y RandomOverSampler*)
- **Utilidades:** `pickle`

---

## üß© Instalaci√≥n

> üí° Se recomienda crear un entorno virtual antes de instalar las dependencias.

Ejecutar el siguiente comando de pip para realizar la instalaci√≥n de las dependencias necesarias para ejecutar los notebooks del proyecto.
```bash
pip install pandas numpy scikit-learn matplotlib seaborn imblearn tensorflow keras xgboost
```

## üóÉÔ∏è Descarga de Datos
Debes asegurarte de que el dataset Proyecto_final.csv est√© disponible en la ruta de ejecuci√≥n o en la ruta especificada dentro del script de exploraci√≥n, como **/content/drive/MyDrive/Proyecto_final.csv** si se usa Google Colab como entorno virtual.

---

## üöÄ Ejecuci√≥n del C√≥digo

El proyecto sigue un flujo que comienza con la inspecci√≥n de los datos y contin√∫a con el entrenamiento y la evaluaci√≥n de modelos.

### 1Ô∏è‚É£ Exploraci√≥n y Limpieza

- Abre y ejecuta **`Exploracion de datos.ipynb`**.  
- Este script carga el dataset y lo limpia inicialmente, eliminando identificadores y tratando los valores **999** (que representan nulos o valores especiales).  
- Genera estad√≠sticas descriptivas (como **asimetr√≠a** y **curtosis**) y gr√°ficos de distribuci√≥n y correlaci√≥n para entender las relaciones entre las variables, especialmente las relacionadas con el **MBI** (*Maslach Burnout Inventory*).

---

### 2Ô∏è‚É£ Modelado y Entrenamiento (Independiente)

- Ejecuta cada uno de los archivos de modelo (**`*final.ipynb`** y **`*Proyecto Final.ipynb`**).  
- Cada script se encarga de realizar el preprocesamiento espec√≠fico que requiere, incluyendo:
  - Selecci√≥n de caracter√≠sticas clave (como *SelectKBest* en SVM o la importancia de *Random Forest* en KNN).  
  - Aplicaci√≥n de t√©cnicas de balanceo (*SMOTE* o *RandomOverSampler*).  
  - Entrenamiento robusto mediante validaci√≥n cruzada (*Cross Validation*).  


---

## üìà M√©tricas de Evaluaci√≥n Utilizadas

Los modelos fueron entrenados y evaluados utilizando las siguientes m√©tricas, adecuadas para sus respectivas tareas de **Clasificaci√≥n** (predicci√≥n de `MBI_Burnout`) y **Regresi√≥n** (predicci√≥n de `MBI_RiesgoBurnout1`):

### üîπ Clasificaci√≥n (DNN, KNN, SVM, XGBoost)
- **Accuracy**  
- **Precision**  
- **Recall**  
- **F1-Score**  
- **ROC-AUC** (*Area Under the Receiver Operating Characteristic Curve*)  
- **Loss** (*binary_crossentropy*)

### üîπ Regresi√≥n (DNN, XGBoost)
- **R¬≤ Score**  
- **MAE** (*Mean Absolute Error*)  
- **MSE** (*Mean Squared Error*)  
- **RMSE** (*Root Mean Squared Error*)

---

## üìö Citaciones

- **Datos:** [PLACEHOLDER: Fuente original del dataset `Proyecto_final.csv`]  

- **Modelos de Referencia:** [PLACEHOLDER: Referencias clave para MBI, PERMA, LGS, etc.]
- **MBI (Maslach Burnout Inventory):**  
  Maslach, C., Jackson, S. E., & Leiter, M. P. (1996). *Maslach Burnout Inventory Manual* (3rd ed.). Consulting Psychologists Press.

- **PERMA (Modelo de Bienestar):**  
  Seligman, M. E. P. (2011). *Flourish: A Visionary New Understanding of Happiness and Well-being.* Free Press.

- **LGS (Loyola Generativity Scale):**  
  McAdams, D. P., & de St. Aubin, E. (1992). *A theory of generativity and its assessment through self-report, behavioral acts, and narrative themes in autobiography.* Journal of Personality and Social Psychology, 62(6), 1003‚Äì1015.

- **Tecnolog√≠as:** Documentaci√≥n de [Python](https://www.python.org/), [Scikit-learn](https://scikit-learn.org/stable/), [TensorFlow / Keras](https://www.tensorflow.org/) y [XGBoost](https://xgboost.readthedocs.io/).

---
